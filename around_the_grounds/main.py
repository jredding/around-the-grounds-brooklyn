"""Main entry point for around-the-grounds CLI."""

import argparse
import asyncio
import json
import logging
import subprocess
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import List, Optional

# Load environment variables from .env file
try:
    from dotenv import load_dotenv

    load_dotenv(override=True)
except ImportError:
    # dotenv is optional, fall back to os.environ
    pass

from .config.loader import load_all_sites, load_site_config, load_site_from_path
from .config.settings import get_git_repository_url
from .models import Venue, Event, SiteConfig
from .scrapers.coordinator import ScraperCoordinator, ScrapingError
from .utils.haiku_generator import HaikuGenerator
from .utils.timezone_utils import format_time_with_timezone

# ---------------------------------------------------------------------------
# Backward-compat shim: load_brewery_config still works for existing callers
# (temporal activities, tests, etc.)
# ---------------------------------------------------------------------------
from .models import Brewery, FoodTruckEvent  # noqa: F401 (re-export)


def load_brewery_config(config_path: Optional[str] = None) -> List[Venue]:
    """Load venue configuration from JSON file (backward compat, reads breweries.json)."""
    if config_path is None:
        config_path_obj = Path(__file__).parent / "config" / "breweries.json"
    else:
        config_path_obj = Path(config_path)

    if not config_path_obj.exists():
        raise FileNotFoundError(f"Config file not found: {config_path_obj}")

    with open(config_path_obj, "r") as f:
        config = json.load(f)

    venues = []
    for venue_data in config.get("breweries", []):
        venue = Venue(
            key=venue_data["key"],
            name=venue_data["name"],
            url=venue_data["url"],
            source_type=venue_data.get("source_type", "html"),
            parser_config=venue_data.get("parser_config", {}),
        )
        venues.append(venue)

    return venues


def format_events_output(
    events: List[Event], errors: Optional[List[ScrapingError]] = None
) -> str:
    """Format events and errors for display."""
    output = []

    # Show events
    if events:
        output.append(f"Found {len(events)} events:")
        output.append("")

        current_date = None
        for event in events:
            event_date = event.date.strftime("%A, %B %d, %Y")

            if current_date != event_date:
                if current_date is not None:
                    output.append("")
                output.append(f"üìÖ {event_date}")
                current_date = event_date

            time_str = ""
            if event.start_time:
                time_str = f" {event.start_time.strftime('%I:%M %p')}"
                if event.end_time:
                    time_str += f" - {event.end_time.strftime('%I:%M %p')}"

            # Check if this is an error event (fallback)
            if "Check Instagram" in event.title or "check Instagram" in (
                event.description or ""
            ):
                output.append(
                    f"  ‚ùå {event.title} @ {event.venue_name}{time_str}"
                )
                if event.description:
                    output.append(f"     {event.description}")
            else:
                if event.extraction_method == "ai-vision":
                    output.append(
                        f"  üé´ {event.title} üñºÔ∏èü§ñ @ {event.venue_name}{time_str}"
                    )
                else:
                    output.append(
                        f"  üé´ {event.title} @ {event.venue_name}{time_str}"
                    )
                if event.description:
                    output.append(f"     {event.description}")

    # Show errors
    if errors:
        user_messages = [error.to_user_message() for error in errors]
        user_messages = list(dict.fromkeys(user_messages))
        if events:
            output.append("")
            output.append("‚ö†Ô∏è  Processing Summary:")
            output.append(f"‚úÖ {len(events)} events found successfully")
            output.append(f"‚ùå {len(errors)} venues failed")
        else:
            output.append("‚ùå No events found - all venues failed")

        output.append("")
        output.append("‚ùå Errors:")
        for message in user_messages:
            output.append(f"  ‚Ä¢ {message}")

    if not events and not errors:
        output.append("No events found for the next 7 days.")

    return "\n".join(output)


async def _generate_description_for_today(
    events: List[Event], site: SiteConfig
) -> Optional[str]:
    """Generate a haiku for today's events (only if site.generate_description is True)."""
    if not site.generate_description:
        return None
    try:
        from .utils.timezone_utils import now_in_pacific_naive

        today_pacific = now_in_pacific_naive()
        today = today_pacific.date()

        today_events = [event for event in events if event.date.date() == today]

        if not today_events:
            logging.getLogger(__name__).debug("No events for today to generate haiku")
            return None

        haiku_generator = HaikuGenerator()
        haiku = await haiku_generator.generate_haiku(
            today_pacific, today_events, max_retries=2, site_name=site.name
        )

        return haiku

    except Exception as e:
        logging.getLogger(__name__).warning(
            f"Failed to generate description, continuing without it: {e}"
        )
        return None


async def _generate_haiku_for_today(events: List[Event]) -> Optional[str]:
    """Backward-compat wrapper: generate haiku without site context."""
    from .models.site import SiteConfig

    dummy_site = SiteConfig(
        key="default",
        name="Food Trucks",
        template="food-trucks",
        timezone="America/Los_Angeles",
        venues=[],
        generate_description=True,
    )
    return await _generate_description_for_today(events, dummy_site)


async def generate_web_data(
    events: List[Event],
    error_messages: Optional[List[str]] = None,
    site: Optional[SiteConfig] = None,
) -> dict:
    """Generate web-friendly JSON data from events."""
    web_events = []
    tz_label = "PT"
    tz_note = "All event times are in Pacific Time (PT)."
    site_name = site.name if site else "Events"
    site_key = site.key if site else "events"
    site_tz = site.timezone if site else "America/Los_Angeles"

    for event in events:
        web_event = {
            "date": event.date.isoformat(),
            "title": event.title,
            "venue": event.venue_name,
            "start_time": (
                format_time_with_timezone(event.start_time, include_timezone=True)
                if event.start_time
                else None
            ),
            "end_time": (
                format_time_with_timezone(event.end_time, include_timezone=True)
                if event.end_time
                else None
            ),
            "start_time_raw": (
                event.start_time.strftime("%I:%M %p").lstrip("0")
                if event.start_time
                else None
            ),
            "end_time_raw": (
                event.end_time.strftime("%I:%M %p").lstrip("0")
                if event.end_time
                else None
            ),
            "description": event.description,
            "extraction_method": event.extraction_method,
            # Legacy keys for backward compat with existing templates
            "vendor": (
                f"{event.title} üñºÔ∏èü§ñ"
                if event.extraction_method == "ai-vision"
                else event.title
            ),
            "location": event.venue_name,
        }
        web_events.append(web_event)

    unique_error_messages = list(dict.fromkeys(error_messages or []))

    # Generate description if site opts in
    description = None
    if site:
        description = await _generate_description_for_today(events, site)
    else:
        # Legacy path: try to generate haiku without site context
        try:
            from .utils.timezone_utils import now_in_pacific_naive

            today_pacific = now_in_pacific_naive()
            today = today_pacific.date()
            today_events = [e for e in events if e.date.date() == today]
            if today_events:
                haiku_generator = HaikuGenerator()
                description = await haiku_generator.generate_haiku(
                    today_pacific, today_events, max_retries=2
                )
        except Exception:
            pass

    return {
        "events": web_events,
        "updated": datetime.now(timezone.utc).isoformat(),
        "total_events": len(web_events),
        "site_name": site_name,
        "site_key": site_key,
        "timezone": site_tz,
        "timezone_note": tz_note,
        "errors": unique_error_messages,
        "haiku": description,
    }


async def deploy_to_web(
    events: List[Event],
    errors: Optional[List[ScrapingError]] = None,
    git_repo_url: Optional[str] = None,
    site: Optional[SiteConfig] = None,
) -> bool:
    """Generate web data and deploy to Vercel via git."""
    try:
        # Determine target repo
        repo_url = git_repo_url
        if not repo_url and site and site.target_repo:
            repo_url = site.target_repo
        repository_url = get_git_repository_url(repo_url)

        error_messages = [error.to_user_message() for error in errors or []]
        error_messages = list(dict.fromkeys(error_messages))
        web_data = await generate_web_data(events, error_messages, site)

        print(f"‚úÖ Generated web data: {len(events)} events")
        print(f"üìç Target repository: {repository_url}")

        # Determine template directory
        if site:
            template_dir_name = site.template
        else:
            template_dir_name = "food-trucks"

        return _deploy_with_github_auth(web_data, repository_url, template_dir_name)

    except subprocess.CalledProcessError as e:
        print(f"‚ùå Deployment failed: {e}")
        return False
    except Exception as e:
        print(f"‚ùå Error during deployment: {e}")
        return False


def _deploy_with_github_auth(
    web_data: dict, repository_url: str, template_dir_name: str = "food-trucks"
) -> bool:
    """Deploy web data to git repository using GitHub App authentication."""
    import shutil
    import tempfile

    from .utils.github_auth import GitHubAppAuth

    try:
        print("üîê Using GitHub App authentication for deployment...")

        with tempfile.TemporaryDirectory() as temp_dir:
            repo_dir = Path(temp_dir) / "repo"

            print(f"üì• Cloning repository {repository_url}...")
            subprocess.run(
                ["git", "clone", repository_url, str(repo_dir)],
                check=True,
                capture_output=True,
            )

            subprocess.run(
                ["git", "config", "user.email", "steve.androulakis@gmail.com"],
                cwd=repo_dir,
                check=True,
                capture_output=True,
            )
            subprocess.run(
                ["git", "config", "user.name", "Around the Grounds Bot"],
                cwd=repo_dir,
                check=True,
                capture_output=True,
            )

            # Copy template files ‚Äî try new multi-template path first, fall back to legacy
            public_templates_dir = Path.cwd() / "public_templates" / template_dir_name
            if not public_templates_dir.exists():
                public_templates_dir = Path.cwd() / "public_template"

            target_public_dir = repo_dir / "public"

            print(f"üìã Copying template files from {public_templates_dir}...")
            shutil.copytree(public_templates_dir, target_public_dir, dirs_exist_ok=True)

            json_path = target_public_dir / "data.json"
            with open(json_path, "w") as f:
                json.dump(web_data, f, indent=2)

            print(f"üìù Updated data.json with {web_data.get('total_events', 0)} events")

            subprocess.run(
                ["git", "add", "public/"], cwd=repo_dir, check=True, capture_output=True
            )

            result = subprocess.run(
                ["git", "diff", "--staged", "--quiet"],
                cwd=repo_dir,
                capture_output=True,
            )
            if result.returncode == 0:
                print("‚ÑπÔ∏è  No changes to deploy")
                return True

            site_name = web_data.get("site_name", "Events")
            commit_msg = f"üìÖ Update {site_name} - {datetime.now().strftime('%Y-%m-%d %H:%M')}"
            subprocess.run(
                ["git", "commit", "-m", commit_msg],
                cwd=repo_dir,
                check=True,
                capture_output=True,
            )

            auth = GitHubAppAuth(repository_url)
            access_token = auth.get_access_token()

            authenticated_url = f"https://x-access-token:{access_token}@github.com/{auth.repo_owner}/{auth.repo_name}.git"
            subprocess.run(
                ["git", "remote", "set-url", "origin", authenticated_url],
                cwd=repo_dir,
                check=True,
                capture_output=True,
            )

            print(f"üöÄ Pushing to {repository_url}...")
            subprocess.run(
                ["git", "push", "origin", "main"],
                cwd=repo_dir,
                check=True,
                capture_output=True,
            )
            print("‚úÖ Deployed successfully! Changes will be live shortly.")

            return True

    except subprocess.CalledProcessError as e:
        error_msg = e.stderr.decode("utf-8") if e.stderr else str(e)
        print(f"‚ùå Git operation failed: {error_msg}")
        return False
    except Exception as e:
        print(f"‚ùå Error during deployment: {e}")
        return False


async def preview_locally(
    events: List[Event],
    errors: Optional[List[ScrapingError]] = None,
    site: Optional[SiteConfig] = None,
) -> bool:
    """Generate web files locally in public/ directory for preview."""
    import shutil

    try:
        error_messages = [error.to_user_message() for error in errors or []]
        error_messages = list(dict.fromkeys(error_messages))
        web_data = await generate_web_data(events, error_messages, site)

        # Determine template directory
        if site:
            template_dir_name = site.template
        else:
            template_dir_name = "food-trucks"

        public_templates_dir = Path.cwd() / "public_templates" / template_dir_name
        if not public_templates_dir.exists():
            public_templates_dir = Path.cwd() / "public_template"

        local_public_dir = Path.cwd() / "public"

        if not public_templates_dir.exists():
            print(f"‚ùå Template directory not found: {public_templates_dir}")
            return False

        if local_public_dir.exists():
            shutil.rmtree(local_public_dir)

        print(f"üìã Copying template files from {public_templates_dir}...")
        shutil.copytree(public_templates_dir, local_public_dir)

        json_path = local_public_dir / "data.json"
        with open(json_path, "w") as f:
            json.dump(web_data, f, indent=2)

        print(f"‚úÖ Generated local preview: {len(events)} events")
        print(f"üìÅ Preview files in: {local_public_dir}")
        print("üåê To serve locally: cd public && python -m http.server 8000")
        print("üîó Then visit: http://localhost:8000")

        return True

    except Exception as e:
        print(f"‚ùå Error during local preview generation: {e}")
        return False


async def scrape_site(site: SiteConfig) -> tuple:
    """Scrape events for a given site config."""
    if not site.venues:
        return [], []

    coordinator = ScraperCoordinator()
    events = await coordinator.scrape_all(site.venues, timezone=site.timezone)
    errors = coordinator.get_errors()

    return events, errors


async def scrape_food_trucks(config_path: Optional[str] = None) -> tuple:
    """Backward-compat wrapper: scrape using breweries.json or a given path."""
    venues = load_brewery_config(config_path)

    if not venues:
        print("No venues configured.")
        return [], []

    coordinator = ScraperCoordinator()
    events = await coordinator.scrape_all(venues)
    errors = coordinator.get_errors()

    return events, errors


async def async_main(args: argparse.Namespace) -> int:
    """Async main entry point."""
    site_key: Optional[str] = getattr(args, "site", None)
    config_path: Optional[str] = getattr(args, "config", None)

    # Determine which sites to run
    sites: List[SiteConfig] = []

    if config_path:
        # Legacy --config path: load a single site or fall back to old breweries.json
        config_p = Path(config_path)
        try:
            site = load_site_from_path(config_p)
            sites = [site]
        except (FileNotFoundError, KeyError):
            # It's a breweries.json style config ‚Äî wrap it
            events, errors = await scrape_food_trucks(config_path)
            output = format_events_output(events, errors)
            print(output)
            if args.deploy and events:
                await deploy_to_web(events, errors, getattr(args, "git_repo", None))
            if args.preview and events:
                await preview_locally(events, errors)
            return 0 if not errors else (1 if not events else 2)
    elif site_key == "all":
        sites = load_all_sites()
        if not sites:
            print("No site configs found in config/sites/")
            return 1
    elif site_key:
        try:
            sites = [load_site_config(site_key)]
        except FileNotFoundError:
            print(f"‚ùå Site '{site_key}' not found in config/sites/")
            return 1
    else:
        # Default: ballard-food-trucks (backward compat)
        try:
            sites = [load_site_config("ballard-food-trucks")]
        except FileNotFoundError:
            # Fall back to old breweries.json
            events, errors = await scrape_food_trucks()
            output = format_events_output(events, errors)
            print(output)
            if args.deploy and events:
                await deploy_to_web(events, errors, getattr(args, "git_repo", None))
            if args.preview and events:
                await preview_locally(events, errors)
            return 0 if not errors else (1 if not events else 2)

    overall_exit = 0
    for site in sites:
        if len(sites) > 1:
            print(f"\n{'='*50}")
            print(f"üåê {site.name}")
            print("=" * 50)

        events, errors = await scrape_site(site)
        output = format_events_output(events, errors)
        print(output)

        if args.deploy and events:
            await deploy_to_web(
                events, errors, getattr(args, "git_repo", None), site=site
            )

        if args.preview:
            await preview_locally(events, errors, site=site)

        if errors and not events:
            overall_exit = 1
        elif errors:
            overall_exit = max(overall_exit, 2)

    return overall_exit


def main(argv: Optional[List[str]] = None) -> int:
    """Main entry point for the CLI."""
    parser = argparse.ArgumentParser(
        description="Track event schedules across multiple sites"
    )
    parser.add_argument("--version", action="version", version="%(prog)s 0.1.0")
    parser.add_argument(
        "--site",
        "-s",
        help=(
            'Site key to run (e.g. "ballard-food-trucks", "park-slope-music"). '
            'Use "all" to run all configured sites. Default: ballard-food-trucks'
        ),
    )
    parser.add_argument(
        "--config", "-c", help="Path to site or brewery configuration JSON file"
    )
    parser.add_argument(
        "--verbose", "-v", action="store_true", help="Enable verbose logging"
    )
    parser.add_argument(
        "--deploy",
        "-d",
        action="store_true",
        help="Deploy results to web (generate JSON and push to git)",
    )
    parser.add_argument(
        "--git-repo",
        help="Git repository URL for deployment override",
    )
    parser.add_argument(
        "--preview",
        "-p",
        action="store_true",
        help="Generate web files locally in public/ directory for preview",
    )

    args = parser.parse_args(argv)

    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(
        level=log_level, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )

    print("üåê Around the Grounds - Event Tracker")
    print("=" * 50)

    try:
        return asyncio.run(async_main(args))
    except Exception as e:
        print(f"Critical Error: {e}")
        if args.verbose:
            import traceback

            traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
